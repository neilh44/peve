<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MedSchedule AI Assistant</title>
    <style>
        body {
            font-family: 'Inter', sans-serif;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f8fafc;
        }
        .header {
            text-align: center;
            margin-bottom: 30px;
            padding: 20px;
            background-color: #fff;
            border-radius: 12px;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.05);
        }
        .title {
            color: #1e40af;
            margin: 0;
            font-size: 24px;
        }
        .subtitle {
            color: #64748b;
            margin: 10px 0 0;
            font-size: 16px;
        }
        .main-container {
            display: grid;
            grid-template-columns: 300px 1fr;
            gap: 20px;
        }
        .sidebar {
            background-color: #fff;
            padding: 20px;
            border-radius: 12px;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.05);
        }
        .quick-actions {
            list-style: none;
            padding: 0;
            margin: 0;
        }
        .quick-actions li {
            margin-bottom: 10px;
        }
        .quick-actions button {
            width: 100%;
            padding: 12px;
            text-align: left;
            background-color: #f1f5f9;
            border: none;
            border-radius: 6px;
            color: #334155;
            cursor: pointer;
            transition: all 0.2s;
        }
        .quick-actions button:hover {
            background-color: #e2e8f0;
        }
        #chat-container {
            background-color: white;
            border-radius: 12px;
            padding: 20px;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.05);
            height: 500px;
            overflow-y: auto;
            display: flex;
            flex-direction: column;
        }
        .message {
            margin: 10px 0;
            padding: 15px;
            border-radius: 8px;
            max-width: 80%;
        }
        .user {
            background-color: #e0e7ff;
            margin-left: auto;
            color: #1e40af;
        }
        .assistant {
            background-color: #f1f5f9;
            margin-right: auto;
            color: #334155;
        }
        .controls-container {
            background-color: #fff;
            padding: 20px;
            border-radius: 12px;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.05);
            margin-top: 20px;
            text-align: center;
        }
        #speakButton {
            padding: 12px 24px;
            font-size: 16px;
            border: none;
            border-radius: 8px;
            background-color: #2563eb;
            color: white;
            cursor: pointer;
            transition: all 0.2s;
            display: flex;
            align-items: center;
            justify-content: center;
            margin: 0 auto;
        }
        #speakButton:hover {
            background-color: #1d4ed8;
        }
        #speakButton.speaking {
            background-color: #dc2626;
        }
        #status {
            margin-top: 10px;
            color: #64748b;
            font-size: 14px;
        }
        .appointment-details {
            margin-top: 20px;
            padding: 15px;
            background-color: #f8fafc;
            border-radius: 8px;
            display: none;
        }
        .appointment-details.active {
            display: block;
        }
    </style>
</head>
<body>
    <div class="header">
        <h1 class="title">MedSchedule AI Assistant</h1>
        <p class="subtitle">Voice-Enabled Appointment Scheduling System</p>
    </div>
    
    <div class="main-container">
        <div class="sidebar">
            <h3>Quick Actions</h3>
            <ul class="quick-actions">
                <li><button onclick="suggestPrompt('Schedule a new appointment')">Schedule Appointment</button></li>
                <li><button onclick="suggestPrompt('Check available time slots')">Check Availability</button></li>
                <li><button onclick="suggestPrompt('Reschedule my appointment')">Reschedule Appointment</button></li>
                <li><button onclick="suggestPrompt('Cancel my appointment')">Cancel Appointment</button></li>
                <li><button onclick="suggestPrompt('Get appointment reminder')">Set Reminder</button></li>
            </ul>
            
            <div class="appointment-details" id="appointmentDetails">
                <!-- Dynamically filled when appointment is being scheduled -->
            </div>
        </div>
        
        <div class="chat-section">
            <div id="chat-container"></div>
            
            <div class="controls-container">
                <button id="speakButton" onclick="toggleConversation()">
                    Start Voice Assistant
                </button>
                <div id="status">Not connected</div>
            </div>
        </div>
    </div>

    <script>
        let ws;
        let recognition = null;
        let isConnected = false;
        let isListening = false;
        let conversationPaused = true;  // Start paused
        let microphoneStream = null;
        let processingResponse = false;
        let audioContext = null;
        let hasSetup = false;

        // Initialize WebSocket connection
        function connectWebSocket() {
            console.log('Attempting to connect WebSocket...');
            ws = new WebSocket('wss://peve.onrender.com/ws');            
            ws.onopen = () => {
                console.log('WebSocket connection established successfully');
                isConnected = true;
                updateStatus('Connected');
                document.getElementById('speakButton').disabled = false;
            };

            ws.onclose = () => {
                console.log('WebSocket connection closed');
                isConnected = false;
                updateStatus('Disconnected. Reconnecting...');
                document.getElementById('speakButton').disabled = true;
                setTimeout(connectWebSocket, 3000);
            };

            ws.onerror = (error) => {
                console.error('WebSocket error:', error);
                updateStatus('Connection error');
            };

            ws.onmessage = async (event) => {
                console.log('Received message from server:', event.data);
                try {
                    const response = JSON.parse(event.data);
                    if (response.type === 'response') {
                        console.log('Processing response:', response);
                        addMessage(`Assistant: ${response.text}`, 'assistant');
                        
                        // Handle audio playback
                        if (response.audio) {
                            try {
                                // Convert base64 to array buffer
                                const binaryString = atob(response.audio);
                                const len = binaryString.length;
                                const bytes = new Uint8Array(len);
                                for (let i = 0; i < len; i++) {
                                    bytes[i] = binaryString.charCodeAt(i);
                                }
                                
                                console.log('Creating audio blob...');
                                const audioBlob = new Blob([bytes.buffer], { type: 'audio/wav' });
                                const audioUrl = URL.createObjectURL(audioBlob);
                                const audio = new Audio(audioUrl);
                                
                                // Play audio and clean up
                                await audio.play();
                                console.log('Audio playback started');
                                
                                audio.onended = () => {
                                    console.log('Audio playback ended');
                                    URL.revokeObjectURL(audioUrl);
                                    processingResponse = false;
                                    if (!conversationPaused) {
                                        resumeListening();
                                    }
                                };
                            } catch (audioError) {
                                console.error('Error playing audio:', audioError);
                                processingResponse = false;
                                if (!conversationPaused) {
                                    resumeListening();
                                }
                            }
                        } else {
                            processingResponse = false;
                            if (!conversationPaused) {
                                resumeListening();
                            }
                        }
                    }
                } catch (error) {
                    console.error('Error processing message:', error);
                    processingResponse = false;
                }
            };
        }


        // Combined setup function for audio context and recognition
        async function setupAudio() {
            if (hasSetup) return true;

            try {
                // Create audio context
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                
                // Get microphone stream once
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                microphoneStream = stream;

                // Setup recognition with the existing stream
                window.SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
                recognition = new window.SpeechRecognition();
                
                // Modified recognition settings
                recognition.continuous = true;  // Changed to true
                recognition.interimResults = false;
                recognition.lang = 'en-US';
                
                recognition.onresult = (event) => {
                    const transcript = event.results[event.results.length - 1][0].transcript;
                    addMessage(`You: ${transcript}`, 'user');
                    if (ws && ws.readyState === WebSocket.OPEN) {
                        processingResponse = true;
                        ws.send(JSON.stringify({
                            type: 'transcription',
                            text: transcript
                        }));
                    }
                };

                recognition.onend = async () => {
                    isListening = false;
                    if (!conversationPaused && !processingResponse) {
                        await resumeListening();
                    }
                };

                recognition.onerror = async (event) => {
                    console.error('Recognition error:', event.error);
                    isListening = false;
                    
                    if (event.error === 'not-allowed') {
                        hasSetup = false;
                        stopAllAudio();
                        alert('Microphone permission was denied. Please enable microphone access and try again.');
                        return;
                    }
                    
                    if (event.error !== 'no-speech' && !conversationPaused && !processingResponse) {
                        await resumeListening();
                    }
                };

                hasSetup = true;
                return true;
            } catch (error) {
                console.error('Setup error:', error);
                hasSetup = false;
                return false;
            }
        }

        async function resumeListening() {
            if (!isListening && !conversationPaused && !processingResponse) {
                try {
                    await recognition.start();
                    isListening = true;
                    updateStatus('Listening...');
                } catch (err) {
                    if (err.name === 'InvalidStateError') {
                        // Recognition is already started, ignore this error
                        isListening = true;
                    } else {
                        console.error('Error resuming recognition:', err);
                        updateStatus('Error starting recognition');
                    }
                }
            }
        }

        function stopAllAudio() {
            if (recognition) {
                recognition.stop();
            }
            if (microphoneStream) {
                microphoneStream.getTracks().forEach(track => track.stop());
            }
            if (audioContext) {
                audioContext.close();
            }
            microphoneStream = null;
            audioContext = null;
            recognition = null;
            hasSetup = false;
        }

        // Toggle conversation state
        async function toggleConversation() {
            if (!hasSetup) {
                const setupSuccess = await setupAudio();
                if (!setupSuccess) {
                    alert('Could not set up audio. Please ensure microphone permissions are granted.');
                    return;
                }
            }

            conversationPaused = !conversationPaused;
            processingResponse = false;
            const button = document.getElementById('speakButton');
            
            if (conversationPaused) {
                button.textContent = 'Resume Conversation';
                button.classList.add('speaking');
                updateStatus('Paused');
                if (recognition) {
                    recognition.stop();
                }
            } else {
                button.textContent = 'Pause Conversation';
                button.classList.remove('speaking');
                await resumeListening();
            }
        }

        // Helper functions
        function addMessage(message, type) {
            const chatContainer = document.getElementById('chat-container');
            const messageDiv = document.createElement('div');
            messageDiv.className = `message ${type}`;
            messageDiv.textContent = message;
            chatContainer.appendChild(messageDiv);
            chatContainer.scrollTop = chatContainer.scrollHeight;
        }

        function updateStatus(status) {
            document.getElementById('status').textContent = status;
        }

        // Initialize the application
        window.onload = () => {
            document.getElementById('speakButton').disabled = true;
            connectWebSocket();
        };

        // Cleanup on page unload
        window.onunload = () => {
            stopAllAudio();
            if (ws) {
                ws.close();
            }
        };
    </script>
</body>
</html>
